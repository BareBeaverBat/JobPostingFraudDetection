{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "define how to handle raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#CSV column indices\n",
    "\n",
    "TITLE_INDEX = 1\n",
    "LOCATION_INDEX=2\n",
    "DEPARTMENT_INDEX=3\n",
    "SALARY_INDEX=4\n",
    "COMPANY_PROFILE_INDEX=5\n",
    "DESCRIPTION_INDEX=6\n",
    "REQUIREMENTS_INDEX=7\n",
    "BENEFITS_INDEX=8\n",
    "TELECOMMUTING_INDEX=9\n",
    "HAS_LOGO_INDEX = 10\n",
    "HAS_QUESTIONS_INDEX= 11\n",
    "EMPLOYMENT_TYPE_INDEX=12\n",
    "REQUIRED_EXPERIENCE_INDEX=13\n",
    "REQUIRED_EDUCATION_INDEX=14\n",
    "INDUSTRY_INDEX=15\n",
    "FUNCTION_INDEX=16\n",
    "FRAUDULENT_INDEX=17\n",
    "\n",
    "#Dataframe labels\n",
    "\n",
    "TITLE_LABEL=\"title\"\n",
    "LOCATION_LABEL=\"location\"\n",
    "DEPARTMENT_LABEL=\"department\"\n",
    "COMPANY_PROFILE_LABEL=\"company_profile\"\n",
    "DESCRIPTION_LABEL=\"description\"\n",
    "REQUIREMENTS_LABEL=\"requirements\"\n",
    "BENEFITS_LABEL=\"benefits\"\n",
    "\n",
    "MIN_SALARY_LABEL=\"min_salary\"\n",
    "MAX_SALARY_LABEL=\"max_salary\"\n",
    "SALARY_RANGE_LABEL=\"salary_range\"\n",
    "SALARY_MIDPT_LABEL=\"salary_midpt\"\n",
    "\n",
    "EMPLOYMENT_TYPE_LABEL=\"employment_type\"\n",
    "REQUIRED_EXPERIENCE_LABEL=\"required_experience\"\n",
    "REQUIRED_EDUCATION_LABEL=\"required_education\"\n",
    "INDUSTRY_LABEL=\"industry\"\n",
    "FUNCTION_LABEL=\"function\"\n",
    "\n",
    "TELECOMMUTING_LABEL=\"telecommuting\"\n",
    "HAS_LOGO_LABEL = \"has_logo\"\n",
    "HAS_QUESTIONS_LABEL= \"has_questions\"\n",
    "\n",
    "FRAUDULENT_LABEL=\"IS_FRAUDULENT\"\n",
    "\n",
    "#salary processing constants\n",
    "\n",
    "SALARY_RANGE_REGEX = re.compile(r\"\\d+-\\d+\")\n",
    "SALARY_VAL_REGEX= re.compile(r\"\\d+\")\n",
    "\n",
    "\n",
    "#text preprocessing hyperparameters\n",
    "\n",
    "baselineStopwords = [] #TODO\n",
    "NONALPHANUMERIC_REGEX= re.compile(r\"[^A-Za-z0-9^,!.\\/'+-=]\")\n",
    "\n",
    "\n",
    "MULT_WHITESPACE_REGEX= re.compile(r\"\\s{2,}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def findOrAdd(givenList, givenVal):\n",
    "    ind = -1\n",
    "    for i, currVal in enumerate(givenList):\n",
    "        if currVal == givenVal:\n",
    "            ind= i\n",
    "            break\n",
    "    if ind == -1:\n",
    "        givenList.append(givenVal)\n",
    "        ind= len(givenList) -1\n",
    "\n",
    "    return ind\n",
    "\n",
    "#classes for handling summary data from the data loading/preprocessing\n",
    "class CategoriesSummary:\n",
    "    def __init__(self):\n",
    "        self.employmentTypeVals = []\n",
    "        self.requiredExperienceVals = []\n",
    "        self.requiredEducationVals = []\n",
    "        self.industryVals = []\n",
    "        self.functionVals = []\n",
    "\n",
    "    def findOrAddEmploymentType(self, currEmploymentType):\n",
    "        return findOrAdd(self.employmentTypeVals, currEmploymentType)\n",
    "    def findOrAddRequiredExperience(self, currRequiredExperience):\n",
    "        return findOrAdd(self.requiredExperienceVals, currRequiredExperience)\n",
    "    def findOrAddRequiredEducation(self, currRequiredEducation):\n",
    "        return findOrAdd(self.requiredEducationVals, currRequiredEducation)\n",
    "    def findOrAddIndustry(self, currIndustry):\n",
    "        return findOrAdd(self.industryVals, currIndustry)\n",
    "    def findOrAddFunction(self, currFunction):\n",
    "        return findOrAdd(self.functionVals, currFunction)\n",
    "\n",
    "    def saveToFiles(self, dirPath):\n",
    "        employmentTypeOptionsFilePath = os.path.join(dirPath, \"employment_type_options.txt\")\n",
    "        with open(employmentTypeOptionsFilePath) as employmentTypeOptionsFile:\n",
    "            employmentTypeOptionsFile.writelines(self.employmentTypeVals)\n",
    "        \n",
    "        requiredExperienceOptionsFilePath = os.path.join(dirPath, \"required_experience_options.txt\")\n",
    "        with open(requiredExperienceOptionsFilePath) as requiredExperienceOptionsFile:\n",
    "            requiredExperienceOptionsFile.writelines(self.requiredExperienceVals)\n",
    "        \n",
    "        requiredEducationOptionsFilePath = os.path.join(dirPath, \"required_education_options.txt\")\n",
    "        with open(requiredEducationOptionsFilePath) as requiredEducationOptionsFile:\n",
    "            requiredEducationOptionsFile.writelines(self.requiredEducationVals)\n",
    "        \n",
    "        industryOptionsFilePath = os.path.join(dirPath, \"industry_options.txt\")\n",
    "        with open(industryOptionsFilePath) as industryOptionsFile:\n",
    "            industryOptionsFile.writelines(self.industryVals)\n",
    "        \n",
    "        functionOptionsFilePath = os.path.join(dirPath, \"function_options.txt\")\n",
    "        with open(functionOptionsFilePath) as functionOptionsFile:\n",
    "            functionOptionsFile.writelines(self.functionVals)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "class TextAttributeSummaries:\n",
    "    def __init__(self):\n",
    "        self.cumulTitlesText = \"\"\n",
    "        self.cumulLocationsText = \"\"\n",
    "        self.cumulDepartmentsText = \"\"\n",
    "        self.cumulCompanyProfilesText = \"\"\n",
    "        self.cumulDescriptionsText = \"\"\n",
    "        self.cumulRequirementsText = \"\"\n",
    "        self.cumulBenefitsText = \"\"\n",
    "\n",
    "    def addTitle(self, currTitle):\n",
    "        self.cumulTitlesText += currTitle + \" \"\n",
    "    def addLocation(self, currLocation):\n",
    "        self.cumulLocationsText += currLocation + \" \"\n",
    "    def addDepartment(self, currDepartment):\n",
    "        self.cumulDepartmentsText += currDepartment + \" \"\n",
    "    def addCompanyProfile(self, currCompanyProfile):\n",
    "        self.cumulCompanyProfilesText += currCompanyProfile + \" \"\n",
    "    def addDescription(self, currDescription):\n",
    "        self.cumulDescriptionsText += currDescription + \" \"\n",
    "    def addRequirements(self, currRequirements):\n",
    "        self.cumulRequirementsText += currRequirements + \" \"\n",
    "    def addBenefits(self, currBenefits):\n",
    "        self.cumulBenefitsText += currBenefits + \" \"\n",
    "\n",
    "    def saveToFile(self, dirPath):\n",
    "        textAttributeSummariesFilePath = os.path.join(dirPath, \"text_attribute_summaries.txt\")\n",
    "        with open(textAttributeSummariesFilePath) as textAttributeSummariesFile:\n",
    "            textAttributeSummariesFile.write(\"title: %s\\n\" % self.cumulTitlesText)\n",
    "            textAttributeSummariesFile.write(\"location: %s\\n\" % self.cumulLocationsText)\n",
    "            textAttributeSummariesFile.write(\"department: %s\\n\" % self.cumulDepartmentsText)\n",
    "            textAttributeSummariesFile.write(\"company profile: %s\\n\" % self.cumulCompanyProfilesText)\n",
    "            textAttributeSummariesFile.write(\"description: %s\\n\" % self.cumulDescriptionsText)\n",
    "            textAttributeSummariesFile.write(\"requirements: %s\\n\" % self.cumulRequirementsText)\n",
    "            textAttributeSummariesFile.write(\"benefits: %s\\n\" % self.cumulBenefitsText)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#preprocessing functions\n",
    "\n",
    "# based on\n",
    "#  https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
    "def cleanText(rawText, stopwordsList= None, stemmer= None):\n",
    "    processedText = \"\"\n",
    "\n",
    "    processedText= rawText.lower()\n",
    "\n",
    "\n",
    "    processedText = re.sub(NONALPHANUMERIC_REGEX, \" \", processedText)\n",
    "\n",
    "    # TODO review these- with some I'm not sure\n",
    "    #  whether they work as written (raw string vs escape characters?) or whether I want them\n",
    "    processedText = re.sub(r\"what's\", \"what is \", processedText)\n",
    "    processedText = re.sub(r\"\\'s\", \" \", processedText)\n",
    "    processedText = re.sub(r\"\\'ve\", \" have \", processedText)\n",
    "    processedText = re.sub(r\"can't\", \"cannot \", processedText)\n",
    "    processedText = re.sub(r\"n't\", \" not \", processedText)\n",
    "    processedText = re.sub(r\"i'm\", \"i am \", processedText)\n",
    "    processedText = re.sub(r\"\\'re\", \" are \", processedText)\n",
    "    processedText = re.sub(r\"\\'d\", \" would \", processedText)\n",
    "    processedText = re.sub(r\"\\'ll\", \" will \", processedText)\n",
    "    processedText = re.sub(r\",\", \" \", processedText)\n",
    "    processedText = re.sub(r\"\\.\", \" \", processedText)\n",
    "    processedText = re.sub(r\"!\", \" ! \", processedText)\n",
    "    processedText = re.sub(r\"\\/\", \" \", processedText)\n",
    "    processedText = re.sub(r\"\\^\", \" ^ \", processedText)\n",
    "    processedText = re.sub(r\"\\+\", \" + \", processedText)\n",
    "    processedText = re.sub(r\"\\-\", \" - \", processedText)\n",
    "    processedText = re.sub(r\"\\=\", \" = \", processedText)\n",
    "    processedText = re.sub(r\"'\", \" \", processedText)\n",
    "    processedText = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", processedText)\n",
    "    processedText = re.sub(r\":\", \" : \", processedText)\n",
    "    processedText = re.sub(r\" e g \", \" eg \", processedText)\n",
    "    processedText = re.sub(r\" b g \", \" bg \", processedText)\n",
    "    processedText = re.sub(r\" u s \", \" american \", processedText)\n",
    "    processedText = re.sub(r\"\\0s\", \"0\", processedText)\n",
    "    processedText = re.sub(r\" 9 11 \", \"911\", processedText)\n",
    "    processedText = re.sub(r\"e - mail\", \"email\", processedText)\n",
    "    processedText = re.sub(r\"j k\", \"jk\", processedText)\n",
    "\n",
    "    processedText = re.sub(MULT_WHITESPACE_REGEX, \" \", processedText)\n",
    "\n",
    "    #todo does this need to go before the regex?\n",
    "    if stopwordsList is not None:\n",
    "        textArr = processedText.split()\n",
    "        textArr = [currWord for currWord in textArr if not currWord in stopwordsList]\n",
    "        processedText = \" \".join(textArr)\n",
    "\n",
    "    if stemmer is not None:\n",
    "        textArr = processedText.split()\n",
    "        stemmedWords = [stemmer.stem(currWord) for currWord in textArr]\n",
    "        processedText = \" \".join(stemmedWords)\n",
    "\n",
    "    return processedText\n",
    "\n",
    "def processJobListing(rawDataRow, categorySummariesObj, textAttributeSummariesObj):\n",
    "    processedListing = {}\n",
    "\n",
    "\n",
    "    #copy the boolean values\n",
    "    processedListing[TELECOMMUTING_LABEL] = rawDataRow[TELECOMMUTING_INDEX]\n",
    "    processedListing[HAS_LOGO_LABEL] = rawDataRow[HAS_LOGO_INDEX]\n",
    "    processedListing[HAS_QUESTIONS_LABEL] = rawDataRow[HAS_QUESTIONS_INDEX]\n",
    "    processedListing[FRAUDULENT_LABEL] = rawDataRow[FRAUDULENT_INDEX]\n",
    "\n",
    "    #one-hot encode the categorical attributes\n",
    "    currEmploymentType = rawDataRow[EMPLOYMENT_TYPE_INDEX]\n",
    "    currEmploymentTypeInd = categorySummariesObj.findOrAddEmploymentType(currEmploymentType)\n",
    "    processedListing[EMPLOYMENT_TYPE_LABEL] = currEmploymentTypeInd\n",
    "    \n",
    "    currRequiredExperience = rawDataRow[REQUIRED_EXPERIENCE_INDEX]\n",
    "    currRequiredExperienceInd = categorySummariesObj.findOrAddRequiredExperience(currRequiredExperience)\n",
    "    processedListing[REQUIRED_EXPERIENCE_LABEL] = currRequiredExperienceInd\n",
    "    \n",
    "    currRequiredEducation = rawDataRow[REQUIRED_EDUCATION_INDEX]\n",
    "    currRequiredEducationInd = categorySummariesObj.findOrAddRequiredEducation(currRequiredEducation)\n",
    "    processedListing[REQUIRED_EDUCATION_LABEL] = currRequiredEducationInd\n",
    "    \n",
    "    currIndustry = rawDataRow[INDUSTRY_INDEX]\n",
    "    currIndustryInd = categorySummariesObj.findOrAddIndustry(currIndustry)\n",
    "    processedListing[INDUSTRY_LABEL] = currIndustryInd\n",
    "    \n",
    "    currFunction = rawDataRow[FUNCTION_INDEX]\n",
    "    currFunctionInd = categorySummariesObj.findOrAddFunction(currFunction)\n",
    "    processedListing[FUNCTION_LABEL] = currFunctionInd\n",
    "\n",
    "    #process salary attribute, eliminating invalid salary entries\n",
    "    currSalaryText = rawDataRow[SALARY_INDEX]\n",
    "\n",
    "    minSalaryVal = -1\n",
    "    maxSalaryVal = -1\n",
    "    salaryRange= -1\n",
    "    salaryMidpt = -1\n",
    "\n",
    "    if SALARY_RANGE_REGEX.match(currSalaryText):\n",
    "        salaryStrs = currSalaryText.split(\"-\")\n",
    "        minSalaryStr= salaryStrs[0]\n",
    "        maxSalaryStr= salaryStrs[1]\n",
    "\n",
    "        minSalaryVal = float(minSalaryStr)\n",
    "        maxSalaryVal = float(maxSalaryStr)\n",
    "        salaryRange = maxSalaryVal - minSalaryVal\n",
    "        salaryMidpt = (maxSalaryVal + minSalaryVal)/2\n",
    "    elif SALARY_VAL_REGEX.match(currSalaryText):\n",
    "        minSalaryVal = float(currSalaryText)\n",
    "        maxSalaryVal = minSalaryVal\n",
    "        salaryRange = 0\n",
    "        salaryMidpt= minSalaryVal\n",
    "    else:\n",
    "        pass #use default invalid values\n",
    "\n",
    "    processedListing[MIN_SALARY_LABEL] = minSalaryVal\n",
    "    processedListing[MAX_SALARY_LABEL] = maxSalaryVal\n",
    "    processedListing[SALARY_RANGE_LABEL] = salaryRange\n",
    "    processedListing[SALARY_MIDPT_LABEL] = salaryMidpt\n",
    "\n",
    "    #basic processing of text attributes\n",
    "    titleVal = rawDataRow[TITLE_INDEX]\n",
    "    cleanedTitleVal= cleanText(titleVal, baselineStopwords)\n",
    "    processedListing[TITLE_LABEL] = cleanedTitleVal\n",
    "    textAttributeSummariesObj.addTitle(cleanedTitleVal)\n",
    "\n",
    "    locationVal = rawDataRow[LOCATION_INDEX]\n",
    "    cleanedLocationVal =  cleanText(locationVal, baselineStopwords)\n",
    "    processedListing[LOCATION_LABEL] = cleanedLocationVal\n",
    "    textAttributeSummariesObj.addLocation(cleanedLocationVal)\n",
    "\n",
    "    departmentVal = rawDataRow[DEPARTMENT_INDEX]\n",
    "    cleanedDepartmentVal = cleanText(departmentVal, baselineStopwords)\n",
    "    processedListing[DEPARTMENT_LABEL] = cleanedDepartmentVal\n",
    "    textAttributeSummariesObj.addDepartment(cleanedDepartmentVal)\n",
    "\n",
    "    companyProfileVal = rawDataRow[COMPANY_PROFILE_INDEX]\n",
    "    cleanedCompanyProfileVal= cleanText(companyProfileVal, baselineStopwords)\n",
    "    processedListing[COMPANY_PROFILE_LABEL] = cleanedCompanyProfileVal\n",
    "    textAttributeSummariesObj.addCompanyProfile(cleanedCompanyProfileVal)\n",
    "\n",
    "    descriptionVal = rawDataRow[DESCRIPTION_INDEX]\n",
    "    cleanedDescriptionVal = cleanText(descriptionVal, baselineStopwords)\n",
    "    processedListing[DESCRIPTION_LABEL] = cleanedDescriptionVal\n",
    "    textAttributeSummariesObj.addDescription(cleanedDescriptionVal)\n",
    "\n",
    "    requirementsVal = rawDataRow[REQUIREMENTS_INDEX]\n",
    "    cleanedRequirementsVal = cleanText(requirementsVal, baselineStopwords)\n",
    "    processedListing[REQUIREMENTS_LABEL] = cleanedRequirementsVal\n",
    "    textAttributeSummariesObj.addRequirements(cleanedRequirementsVal)\n",
    "\n",
    "    benefitsVal = rawDataRow[BENEFITS_INDEX]\n",
    "    cleanedBenefitsVal = cleanText(benefitsVal, baselineStopwords)\n",
    "    processedListing[BENEFITS_LABEL] = cleanedBenefitsVal\n",
    "    textAttributeSummariesObj.addBenefits(cleanedBenefitsVal)\n",
    "\n",
    "    return processedListing\n",
    "\n",
    "\n",
    "def loadData(fpath):\n",
    "    allCategories = CategoriesSummary()\n",
    "    allTextAttributes = TextAttributeSummaries()\n",
    "    processedData= []\n",
    "\n",
    "    with open(fpath) as raw_csv:\n",
    "        dataReader = csv.reader(raw_csv)\n",
    "        yield next(dataReader) # eliminate header row\n",
    "\n",
    "        #preprocesses the data as it's loaded\n",
    "        for row in dataReader:\n",
    "            processedRow = processJobListing(row, allCategories, allTextAttributes)\n",
    "            processedData.append(processedRow)\n",
    "\n",
    "    return processedData, allCategories, allTextAttributes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', ':', '\\\\', 'U', 's', 'e', 'r', 's', '\\\\', 's', 's', 'i', 'l', 'i', '\\\\', 'P', 'y', 'c', 'h', 'a', 'r', 'm', 'P', 'r', 'o', 'j', 'e', 'c', 't', 's', '\\\\', 'J', 'o', 'b', 'P', 'o', 's', 't', 'i', 'n', 'g', 'F', 'r', 'a', 'u', 'd', 'D', 'e', 't', 'e', 'c', 't', 'i', 'o', 'n', '\\\\', 'd', 'a', 't', 'a', '\\\\', 'p', 'r', 'o', 'c', 'e', 's', 's', 'e', 'd', '\\\\', 'k', 'a', 'g', 'g', 'l', 'e', '_', 'f', 'a', 'k', 'e', '_', 'j', 'o', 'b', '_', 'p', 'o', 's', 't', 'i', 'n', 'g', 's']\n",
      "C:\\Users\\ssili\\PycharmProjects\\JobPostingFraudDetection\\data\\processed\\kaggle_fake_job_postings\n",
      "overwriting directory at path  C:\\Users\\ssili\\PycharmProjects\\JobPostingFraudDetection\\data\\processed\\kaggle_fake_job_postings\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "currDirStr = os.getcwd()\n",
    "currDir = pathlib.Path(currDirStr)\n",
    "projectDir = currDir.parent\n",
    "\n",
    "DATA_PATH = os.path.join(projectDir, \"data\")\n",
    "RAW_DATA_PATH=os.path.join(DATA_PATH, \"raw\")\n",
    "PROCESSED_DATA_PATH= os.path.join(DATA_PATH, \"processed\")\n",
    "\n",
    "PROCESSED_FILE_PREFIX= \"cleaned_\"\n",
    "\n",
    "datasetDirName =\"kaggle_fake_job_postings\"\n",
    "datasetDirPath = os.path.join(PROCESSED_DATA_PATH, datasetDirName)\n",
    "print(list(datasetDirPath))\n",
    "print(datasetDirPath)\n",
    "if os.path.exists(datasetDirPath):\n",
    "    print(\"overwriting directory at path \", datasetDirPath)\n",
    "    os.rmdir(datasetDirPath)\n",
    "os.mkdir(datasetDirPath)\n",
    "\n",
    "testInd = findOrAdd(list(datasetDirPath), \"\\\\\")\n",
    "print(testInd)\n",
    "\n",
    "\n",
    "rawFname = \"fake_job_postings.csv\"\n",
    "rawFpath = os.path.join(RAW_DATA_PATH, rawFname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 4370: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-e2ed52fc333f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcleanedData\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcategorySummaries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtextAttributeSummaries\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloadData\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrawFpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mcleanedDataDf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcleanedData\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-4-959edcbda32c>\u001B[0m in \u001B[0;36mloadData\u001B[1;34m(fpath)\u001B[0m\n\u001B[0;32m    166\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    167\u001B[0m         \u001B[1;31m#preprocesses the data as it's loaded\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 168\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdataReader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    169\u001B[0m             \u001B[0mprocessedRow\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprocessJobListing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallCategories\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallTextAttributes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m             \u001B[0mprocessedData\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocessedRow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\Python37\\lib\\encodings\\cp1252.py\u001B[0m in \u001B[0;36mdecode\u001B[1;34m(self, input, final)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mIncrementalDecoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIncrementalDecoder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfinal\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcharmap_decode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdecoding_table\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mStreamWriter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mCodec\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStreamWriter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m: 'charmap' codec can't decode byte 0x9d in position 4370: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "cleanedData, categorySummaries, textAttributeSummaries = loadData(rawFpath)\n",
    "cleanedDataDf = pd.DataFrame(cleanedData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleanedDataPath = os.path.join(datasetDirPath, PROCESSED_FILE_PREFIX + rawFname)\n",
    "dataSaveResult = cleanedDataDf.to_csv( cleanedDataPath)\n",
    "if dataSaveResult is not None:\n",
    "    print(\"saving dataframe failed with a message (about csv format?): \", dataSaveResult)\n",
    "\n",
    "categorySummaries.saveToFiles(datasetDirPath)\n",
    "textAttributeSummaries.saveToFile(datasetDirPath)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}